{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with Attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dbeWpBWPNhP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2nSmUAHcT97m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jiUhc8-Q0A7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfV9dUj9P6Og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95Hludp1PuL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eX4QJ2WHUkxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnlEz-nPP4E4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "  words = text.split()\n",
        "  return \" \".join(word.lower() for word in words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuYlwpITQzSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "poscount = 0\n",
        "negcount = 0\n",
        "\n",
        "with open('rt-polarity.pos','r',encoding='latin1') as f:\n",
        "  for line in f.readlines():\n",
        "    data.append(preprocess(line[:-1]))\n",
        "    poscount+=1\n",
        "    \n",
        "with open('rt-polarity.neg','r',encoding='latin1') as f:\n",
        "  for line in f.readlines():\n",
        "    data.append(preprocess(line[:-1]))\n",
        "    negcount+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08SOrm9jQuys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = np.zeros(poscount+negcount)\n",
        "labels[:poscount] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ledrGZK2RVcX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data,labels = shuffle(data,labels,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CwswIdRSRirj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traincorpus,testcorpus,trainlabels,testlabels = train_test_split(data,labels,test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9Qq3UCuS7SS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traincorpus,valcorpus,trainlabels,vallabels = train_test_split(traincorpus,trainlabels,test_size=0.1,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p1mF_mACdSeW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(trainlabels)\n",
        "yval = torch.from_numpy(vallabels)\n",
        "ytest = torch.from_numpy(testlabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tzlv7UZfcM-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainlen = len(traincorpus)\n",
        "vallen = len(valcorpus)\n",
        "testlen = len(testcorpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGF1kaFvTHFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for sentence in traincorpus:\n",
        "  words+=sentence.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nkY_aoEUanj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counter = Counter(words).most_common()\n",
        "vocabulary = {}\n",
        "vocabulary['<PAD>'] = 0\n",
        "index = 1\n",
        "for word,_ in counter:\n",
        "  vocabulary[word] = index\n",
        "  index+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAiPS948cbGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_vectors(sentence):\n",
        "  temp = [vocabulary[word] for word in sentence.split() if word in vocabulary]\n",
        "  vector = [0] * maxlen\n",
        "  curlen = len(temp)\n",
        "  if(maxlen-curlen<0):\n",
        "    vector = temp[:maxlen]\n",
        "  else:\n",
        "    vector[maxlen-curlen:] = temp\n",
        "\n",
        "  return torch.from_numpy(np.asarray(vector,dtype='int32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRNIjj-mzOEV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "embeddim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efJo1EvgcD58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xtrain = torch.zeros(trainlen,maxlen)\n",
        "for i in range(trainlen):\n",
        "  Xtrain[i] = get_vectors(traincorpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zzEtcpROdBti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xval = torch.zeros(vallen,maxlen)\n",
        "for i in range(vallen):\n",
        "  Xval[i] = get_vectors(valcorpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvB20cCOdLRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xtest = torch.zeros(testlen,maxlen)\n",
        "for i in range(testlen):\n",
        "  Xtest[i] = get_vectors(testcorpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zBdrncubcDhB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddingindex = {}\n",
        "with open('glove.42B.300d.txt','r',encoding='utf-8') as f:\n",
        "  for line in f.readlines():\n",
        "    vectors = line.split()\n",
        "    word = vectors[0]\n",
        "    embedding = torch.from_numpy(np.asarray(vectors[1:],'float32'))\n",
        "    embeddingindex[word] = embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQcOWQjJcf-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddingmatrix = torch.zeros(len(vocabulary),embeddim)\n",
        "for word,i in list(vocabulary.items()):\n",
        "  if(word in embeddingindex):\n",
        "    embeddingmatrix[i] = embeddingindex[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAdJitrBUc0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hiddendim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDBz4Oe8Qsje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class modelwithattention(nn.Module):\n",
        "  def __init__(self,maxlen,embeddim,embedmatrix,hiddendim,numclasses=1):\n",
        "    super(modelwithattention,self).__init__()\n",
        "    self.maxlen = maxlen\n",
        "    self.embeddim = embeddim\n",
        "    self.embedmatrix = embedmatrix\n",
        "    self.hiddendim = hiddendim\n",
        "    self.numclasses = numclasses\n",
        "    \n",
        "    self.embed = nn.Embedding.from_pretrained(self.embedmatrix)\n",
        "    self.lstm = nn.LSTM(self.embeddim,self.hiddendim,batch_first=True)\n",
        "    self.attlinear = nn.Linear(self.hiddendim,1)\n",
        "    self.linear = nn.Linear(self.hiddendim,self.numclasses)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.soft = nn.Softmax(dim=1)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    \n",
        "  def attention(self,outputs):\n",
        "    outputs_flat = outputs.contiguous().view(-1,self.hiddendim)\n",
        "    alpha = self.attlinear(outputs_flat).view(-1,self.maxlen)\n",
        "    alpha = self.tanh(alpha)\n",
        "    alpha = self.soft(alpha)\n",
        "    att_feature_map = outputs * alpha.unsqueeze(2)\n",
        "    att_feature_map = torch.sum(att_feature_map,dim=1)\n",
        "    return att_feature_map\n",
        "  \n",
        "  def forward(self,x):\n",
        "    embedout = self.embed(x)\n",
        "    lstmout,_ = self.lstm(embedout,None)\n",
        "    attout = self.attention(lstmout)\n",
        "    out = self.sig(self.linear(attout))\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl1rCmwiUTpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attmodel = modelwithattention(maxlen,embeddim,embeddingmatrix,hiddendim).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aap-b9znUu44",
        "colab_type": "code",
        "outputId": "23e7ec57-4333-4ce6-c945-2abd8f41dedf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.ones(4,maxlen).long().to(device)\n",
        "outx = attmodel(x)\n",
        "print(outx.size())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRmM3rb2de0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchsize = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6MdKlxVdVLds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainarray = torch.utils.data.TensorDataset(Xtrain,ytrain)\n",
        "trainloader = torch.utils.data.DataLoader(trainarray,batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eprrh1SYdoeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valarray = torch.utils.data.TensorDataset(Xval,yval)\n",
        "valloader = torch.utils.data.DataLoader(valarray,batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTjAKWzidtwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testarray = torch.utils.data.TensorDataset(Xtest,ytest)\n",
        "testloader = torch.utils.data.DataLoader(testarray,batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfDO2v7ge9Te",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "numepochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNIDL0led_XL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_accuracy(model,loader):\n",
        "  acc = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for indices,labels in loader:\n",
        "      indices = indices.long().to(device)\n",
        "      labels = labels.long().to(device)\n",
        "      \n",
        "      total+=indices.size(0)\n",
        "      output = model(indices).view(labels.size(0))\n",
        "      acc+=torch.sum(labels==(output>0.5).long()).item()\n",
        "      \n",
        "    return ((acc/total)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tN7DfggZfqMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loss(model,loader):\n",
        "  curloss = 0.0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for indices,labels in loader:\n",
        "      indices = indices.long().to(device)\n",
        "      labels = labels.view(-1,1).float().to(device)\n",
        "      \n",
        "      output = model(indices)\n",
        "      curloss+=loss(output,labels)\n",
        "      \n",
        "    return (curloss/len(loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKgVWtnriJvb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(attmodel.parameters(),lr=0.001)\n",
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrnbIw0Tetvl",
        "colab_type": "code",
        "outputId": "517da100-23dc-409b-f21c-d23e62286ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "bestloss = np.Inf\n",
        "best_model_wts = copy.deepcopy(attmodel.state_dict())\n",
        "for epoch in range(numepochs):\n",
        "  attmodel.train()\n",
        "  epochloss = 0.0\n",
        "  epochacc = 0\n",
        "  for indices,labels in trainloader:\n",
        "      indices = indices.long().to(device)\n",
        "      labels = labels.view(-1,1).float().to(device)\n",
        "      \n",
        "      outputs = attmodel(indices)\n",
        "      criterion = loss(outputs,labels)\n",
        "      \n",
        "      epochloss+=criterion.item()\n",
        "      criterion.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "  curloss = get_loss(attmodel,valloader)\n",
        "  curacc = get_accuracy(attmodel,valloader)\n",
        "  print(\"Epoch {} ValLoss {} Val Accuracy {} \".format(epoch+1,curloss,curacc))\n",
        "  if(curloss<bestloss):\n",
        "    bestloss = curloss\n",
        "    best_model_wts = copy.deepcopy(attmodel.state_dict())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ValLoss 0.5528085827827454 Val Accuracy 72.21570926143025 \n",
            "Epoch 2 ValLoss 0.5373021364212036 Val Accuracy 73.5052754982415 \n",
            "Epoch 3 ValLoss 0.5255476832389832 Val Accuracy 74.67760844079719 \n",
            "Epoch 4 ValLoss 0.5187567472457886 Val Accuracy 75.61547479484173 \n",
            "Epoch 5 ValLoss 0.5742065906524658 Val Accuracy 72.21570926143025 \n",
            "Epoch 6 ValLoss 0.5154369473457336 Val Accuracy 75.49824150058618 \n",
            "Epoch 7 ValLoss 0.5653463006019592 Val Accuracy 74.79484173505276 \n",
            "Epoch 8 ValLoss 0.5636205673217773 Val Accuracy 75.96717467760844 \n",
            "Epoch 9 ValLoss 0.6146457195281982 Val Accuracy 76.08440797186401 \n",
            "Epoch 10 ValLoss 0.6108680367469788 Val Accuracy 76.55334114888629 \n",
            "Epoch 11 ValLoss 0.6515982747077942 Val Accuracy 75.61547479484173 \n",
            "Epoch 12 ValLoss 0.6415785551071167 Val Accuracy 75.3810082063306 \n",
            "Epoch 13 ValLoss 0.7198540568351746 Val Accuracy 74.67760844079719 \n",
            "Epoch 14 ValLoss 0.6670474410057068 Val Accuracy 76.31887456037515 \n",
            "Epoch 15 ValLoss 0.7782196402549744 Val Accuracy 74.79484173505276 \n",
            "Epoch 16 ValLoss 0.7538061141967773 Val Accuracy 75.7327080890973 \n",
            "Epoch 17 ValLoss 0.8459194302558899 Val Accuracy 74.20867526377492 \n",
            "Epoch 18 ValLoss 0.7801790833473206 Val Accuracy 77.02227432590855 \n",
            "Epoch 19 ValLoss 0.8363281488418579 Val Accuracy 75.61547479484173 \n",
            "Epoch 20 ValLoss 0.8580211400985718 Val Accuracy 74.91207502930833 \n",
            "Epoch 21 ValLoss 0.8501850366592407 Val Accuracy 75.26377491207504 \n",
            "Epoch 22 ValLoss 0.9114474654197693 Val Accuracy 75.14654161781947 \n",
            "Epoch 23 ValLoss 0.9104261994361877 Val Accuracy 73.73974208675264 \n",
            "Epoch 24 ValLoss 0.9169245362281799 Val Accuracy 74.67760844079719 \n",
            "Epoch 25 ValLoss 0.9622200131416321 Val Accuracy 73.03634232121922 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tsp5UkEkgd6g",
        "colab_type": "code",
        "outputId": "fdf13df7-babd-4028-f78d-d8648f7f8c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "attmodel.load_state_dict(best_model_wts)\n",
        "testacc = get_accuracy(attmodel,testloader)\n",
        "print(\"Test Accuracy {} \".format(testacc))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 76.74636661978434 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GHecbNwbicvo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}