{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with Attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "dbeWpBWPNhP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score,f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2nSmUAHcT97m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jiUhc8-Q0A7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfV9dUj9P6Og",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "95Hludp1PuL3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eX4QJ2WHUkxV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JnlEz-nPP4E4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "  words = text.split()\n",
        "  return \" \".join(word.lower() for word in words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QuYlwpITQzSg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "\n",
        "poscount = 0\n",
        "negcount = 0\n",
        "\n",
        "with open('rt-polarity.pos','r',encoding='latin1') as f:\n",
        "  for line in f.readlines():\n",
        "    data.append(preprocess(line[:-1]))\n",
        "    poscount+=1\n",
        "    \n",
        "with open('rt-polarity.neg','r',encoding='latin1') as f:\n",
        "  for line in f.readlines():\n",
        "    data.append(preprocess(line[:-1]))\n",
        "    negcount+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "08SOrm9jQuys",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels = np.zeros(poscount+negcount)\n",
        "labels[:poscount] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ledrGZK2RVcX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data,labels = shuffle(data,labels,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CwswIdRSRirj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traincorpus,testcorpus,trainlabels,testlabels = train_test_split(data,labels,test_size=0.2,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9Qq3UCuS7SS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traincorpus,valcorpus,trainlabels,vallabels = train_test_split(traincorpus,trainlabels,test_size=0.1,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p1mF_mACdSeW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ytrain = torch.from_numpy(trainlabels)\n",
        "yval = torch.from_numpy(vallabels)\n",
        "ytest = torch.from_numpy(testlabels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tzlv7UZfcM-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainlen = len(traincorpus)\n",
        "vallen = len(valcorpus)\n",
        "testlen = len(testcorpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HGF1kaFvTHFZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for sentence in traincorpus:\n",
        "  words+=sentence.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0nkY_aoEUanj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counter = Counter(words).most_common()\n",
        "vocabulary = {}\n",
        "vocabulary['<PAD>'] = 0\n",
        "index = 1\n",
        "for word,_ in counter:\n",
        "  vocabulary[word] = index\n",
        "  index+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAiPS948cbGp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_vectors(sentence):\n",
        "  temp = [vocabulary[word] for word in sentence.split() if word in vocabulary]\n",
        "  vector = [0] * maxlen\n",
        "  curlen = len(temp)\n",
        "  if(maxlen-curlen<0):\n",
        "    vector = temp[:maxlen]\n",
        "  else:\n",
        "    vector[maxlen-curlen:] = temp\n",
        "\n",
        "  return torch.from_numpy(np.asarray(vector,dtype='int32'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "efJo1EvgcD58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xtrain = torch.zeros(trainlen,maxlen)\n",
        "for i in range(trainlen):\n",
        "  Xtrain[i] = get_vectors(traincorpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zzEtcpROdBti",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xval = torch.zeros(vallen,maxlen)\n",
        "for i in range(vallen):\n",
        "  Xval[i] = get_vectors(valcorpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvB20cCOdLRL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xtest = torch.zeros(testlen,maxlen)\n",
        "for i in range(testlen):\n",
        "  Xtest[i] = get_vectors(testcorpus[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ng4lGHOcbcVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "embeddim = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zBdrncubcDhB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddingindex = {}\n",
        "with open('glove.42B.300d.txt','r',encoding='utf-8') as f:\n",
        "  for line in f.readlines():\n",
        "    vectors = line.split()\n",
        "    word = vectors[0]\n",
        "    embedding = torch.from_numpy(np.asarray(vectors[1:],'float32'))\n",
        "    embeddingindex[word] = embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kQcOWQjJcf-L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddingmatrix = torch.zeros(len(vocabulary),embeddim)\n",
        "for word,i in list(vocabulary.items()):\n",
        "  if(word in embeddingindex):\n",
        "    embeddingmatrix[i] = embeddingindex[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAdJitrBUc0w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hiddendim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDBz4Oe8Qsje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class modelwithattention(nn.Module):\n",
        "  def __init__(self,maxlen,embeddim,embedmatrix,hiddendim,numclasses=1):\n",
        "    super(modelwithattention,self).__init__()\n",
        "    self.maxlen = maxlen\n",
        "    self.embeddim = embeddim\n",
        "    self.embedmatrix = embedmatrix\n",
        "    self.hiddendim = hiddendim\n",
        "    self.numclasses = numclasses\n",
        "    \n",
        "    self.embed = nn.Embedding.from_pretrained(self.embedmatrix)\n",
        "    self.lstm = nn.LSTM(self.embeddim,self.hiddendim,batch_first=True)\n",
        "    self.attlinear = nn.Linear(self.hiddendim*self.maxlen,self.maxlen)\n",
        "    self.linear = nn.Linear(self.hiddendim,self.numclasses)\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.soft = nn.Softmax(dim=1)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    \n",
        "  def attention(self,outputs):\n",
        "    outputs_flat = outputs.contiguous().view(outputs.size(0),-1)\n",
        "    alpha = self.attlinear(outputs_flat)\n",
        "    alpha = self.soft(alpha)\n",
        "    att_feature_map = outputs * alpha.unsqueeze(2)\n",
        "    att_feature_map = torch.sum(att_feature_map,dim=1)\n",
        "    return att_feature_map\n",
        "  \n",
        "  def forward(self,x):\n",
        "    embedout = self.embed(x)\n",
        "    lstmout,_ = self.lstm(embedout,None)\n",
        "    attout = self.attention(lstmout)\n",
        "    out = self.sig(self.linear(attout))\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl1rCmwiUTpT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "attmodel = modelwithattention(maxlen,embeddim,embeddingmatrix,hiddendim).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aap-b9znUu44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d4e2015-f8f1-4479-fff3-8a32575841f4"
      },
      "cell_type": "code",
      "source": [
        "x = torch.ones(4,maxlen).long().to(device)\n",
        "outx = attmodel(x)\n",
        "print(outx.size())"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRmM3rb2de0c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchsize = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6MdKlxVdVLds",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainarray = torch.utils.data.TensorDataset(Xtrain,ytrain)\n",
        "trainloader = torch.utils.data.DataLoader(trainarray,batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eprrh1SYdoeZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "valarray = torch.utils.data.TensorDataset(Xval,yval)\n",
        "valloader = torch.utils.data.DataLoader(valarray,batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KTjAKWzidtwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testarray = torch.utils.data.TensorDataset(Xtest,ytest)\n",
        "testloader = torch.utils.data.DataLoader(testarray,batchsize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfDO2v7ge9Te",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "numepochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lNIDL0led_XL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_accuracy(model,loader):\n",
        "  acc = 0\n",
        "  total = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for indices,labels in loader:\n",
        "      indices = indices.long().to(device)\n",
        "      labels = labels.long().to(device)\n",
        "      \n",
        "      total+=indices.size(0)\n",
        "      output = model(indices).view(labels.size(0))\n",
        "      acc+=torch.sum(labels==(output>0.5).long()).item()\n",
        "      \n",
        "    return ((acc/total)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tN7DfggZfqMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loss(model,loader):\n",
        "  curloss = 0.0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for indices,labels in loader:\n",
        "      indices = indices.long().to(device)\n",
        "      labels = labels.view(-1,1).float().to(device)\n",
        "      \n",
        "      output = model(indices)\n",
        "      curloss+=loss(output,labels)\n",
        "      \n",
        "    return (curloss/len(loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kKgVWtnriJvb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(attmodel.parameters(),lr=0.001)\n",
        "loss = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrnbIw0Tetvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "330428dc-b574-4d0e-e00c-8985c4bcd1d1"
      },
      "cell_type": "code",
      "source": [
        "bestloss = np.Inf\n",
        "best_model_wts = copy.deepcopy(attmodel.state_dict())\n",
        "for epoch in range(numepochs):\n",
        "  attmodel.train()\n",
        "  epochloss = 0.0\n",
        "  epochacc = 0\n",
        "  for indices,labels in trainloader:\n",
        "      indices = indices.long().to(device)\n",
        "      labels = labels.view(-1,1).float().to(device)\n",
        "      \n",
        "      outputs = attmodel(indices)\n",
        "      criterion = loss(outputs,labels)\n",
        "      \n",
        "      epochloss+=criterion.item()\n",
        "      criterion.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "  curloss = get_loss(attmodel,valloader)\n",
        "  curacc = get_accuracy(attmodel,valloader)\n",
        "  print(\"Epoch {} ValLoss {} Val Accuracy {} \".format(epoch+1,curloss,curacc))\n",
        "  if(curloss<bestloss):\n",
        "    bestloss = curloss\n",
        "    best_model_wts = copy.deepcopy(attmodel.state_dict())"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 ValLoss 0.6297080516815186 Val Accuracy 63.77491207502931 \n",
            "Epoch 2 ValLoss 0.6208418607711792 Val Accuracy 67.40914419695193 \n",
            "Epoch 3 ValLoss 0.5610597133636475 Val Accuracy 70.80890973036342 \n",
            "Epoch 4 ValLoss 0.56784987449646 Val Accuracy 73.1535756154748 \n",
            "Epoch 5 ValLoss 0.6306630373001099 Val Accuracy 69.51934349355217 \n",
            "Epoch 6 ValLoss 0.5982494354248047 Val Accuracy 73.38804220398593 \n",
            "Epoch 7 ValLoss 0.6659790277481079 Val Accuracy 70.926143024619 \n",
            "Epoch 8 ValLoss 0.677108645439148 Val Accuracy 71.04337631887456 \n",
            "Epoch 9 ValLoss 0.7540633678436279 Val Accuracy 70.33997655334115 \n",
            "Epoch 10 ValLoss 0.7845807075500488 Val Accuracy 71.51230949589683 \n",
            "Epoch 11 ValLoss 0.7924182415008545 Val Accuracy 71.86400937866354 \n",
            "Epoch 12 ValLoss 0.8623018264770508 Val Accuracy 71.51230949589683 \n",
            "Epoch 13 ValLoss 0.8754377961158752 Val Accuracy 72.21570926143025 \n",
            "Epoch 14 ValLoss 0.8910527229309082 Val Accuracy 70.33997655334115 \n",
            "Epoch 15 ValLoss 0.9331206679344177 Val Accuracy 71.39507620164126 \n",
            "Epoch 16 ValLoss 0.9318369626998901 Val Accuracy 71.6295427901524 \n",
            "Epoch 17 ValLoss 0.9790024161338806 Val Accuracy 71.04337631887456 \n",
            "Epoch 18 ValLoss 1.0168598890304565 Val Accuracy 71.2778429073857 \n",
            "Epoch 19 ValLoss 1.006671667098999 Val Accuracy 70.57444314185229 \n",
            "Epoch 20 ValLoss 0.9970871210098267 Val Accuracy 71.39507620164126 \n",
            "Epoch 21 ValLoss 0.9925904273986816 Val Accuracy 70.80890973036342 \n",
            "Epoch 22 ValLoss 0.9323267936706543 Val Accuracy 71.86400937866354 \n",
            "Epoch 23 ValLoss 0.9794438481330872 Val Accuracy 71.2778429073857 \n",
            "Epoch 24 ValLoss 1.0026600360870361 Val Accuracy 71.2778429073857 \n",
            "Epoch 25 ValLoss 1.0342284440994263 Val Accuracy 67.29191090269636 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tsp5UkEkgd6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a534f867-abbd-448c-bfdc-4a92144a34c4"
      },
      "cell_type": "code",
      "source": [
        "attmodel.load_state_dict(best_model_wts)\n",
        "testacc = get_accuracy(attmodel,testloader)\n",
        "print(\"Test Accuracy {} \".format(testacc))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 72.38631036099392 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GHecbNwbicvo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}